%! TeX program = lualatex

\documentclass[sigplan,screen,anonymous]{acmart}

\usepackage{fontspec}
\usepackage{bytefield}
\usepackage{tikz}
\usepackage{hyperref}
\usepackage{url}

\begin{document}

% https://mirror.math.princeton.edu/pub/CTAN/macros/unicodetex/latex/fontspec/fontspec.pdf
\setmonofont{Jet Brains Mono}[Scale=MatchUppercase]

\begin{abstract}
    Array languages like J and APL suffer from a lack of embeddability in implementations.
    Here we present statically determined memory allocation for flat, immutable arrays used in the Apple array system, a JIT compiler for an expression-oriented functional language.
    The method is a straightforward extension of liveness analysis familiar to compiler writers.
    Ownership is simple and Apple does not constrain memory management in the host language.
    Two implementations---one in Python and one in R--- are exhibited.
\end{abstract}

\title{Apple Array Allocation}
\orcid{0000-0001-6093-2967}
\author{V. E. McHale}
\affiliation{%
\institution{Northern Trust}
  \streetaddress{50 South LaSalle Street}
  \city{Chicago}
  \state{IL}
  \postcode{60603}
  \country{USA}
}
\email{vamchale@gmail.com}
\maketitle

\section{Introduction}

\subsection{Background}

Array languages such as APL and J suffer from undeserved obscurity \cite{hsu2023}. In order to make them more useful to enthusiasts, one might hope to embed them, thus providing access to developed libraries, e.g. matplotlib \cite{hunter2007}.

% conversely, array languages are good candidates for a new style of compiler because

APL implementations typically use reference-counting \cite[p.~47]{hui2020} for performance reasons, but this imposes on the calling code---one must increment the reference count and delegate each array to a garbage collector. Our arrays are pointers managed by the system's {\tt malloc} and {\tt free}. By providing a primitive interface we grant the host language a more equal status; this is arguably how C has succeeded \cite{kell2017} and how APL on .NET failed \cite[p.~12]{hui2020}.

\subsection{Apple Array System}

The Apple JIT compiler is a function
\begin{verbatim}
apple_compile :: ( FunPtr (CSize -> Ptr a)
                 , FunPtr (Ptr a -> ())
                 )
              -> String -> Bytes
\end{verbatim}
taking a pointer to {\tt malloc}, a pointer to {\tt free}, and source code as input and returning machine code; the compiler only generates these two foreign function calls and there is no runtime system.

This simplifies linking in the JIT; the lack of a garbage collector makes for a good example exploring compiler architectures---one could imagine compiling on one computer and then sending machine code elsewhere for execution.

\subsubsection{Language}

The language is expression-oriented and all data are immutable. Recursion is not supported; all looping is implicit. This is hardly burdensome for array programmers, who favor vector solutions already \cite[Chapter.~31]{stokes2015}.

The below computes the Kullback-Liebler divergence using a fold and a zip:
\begin{verbatim}
\p.\q. (+)/([x*_.(x%y)]`p q)
\end{verbatim}
In general, the language has the scope of a calculator, plus select array operations.

\subsubsection{Flat Array Types}

Apple arrays are completely flat in memory, consisting of rank, dimensions, and data laid out contiguously.

A {\tt 2x4} array:

\begin{bytefield}[bitwidth=0.075\linewidth]{11}
    \\
    \bitheader{0-10} \\
    \bitbox{1}{2} & \bitbox{1}{2} & \bitbox{1}{4} & \bitbox{1}{$a_{00}$} & \bitbox{1}{$a_{01}$} & \bitbox{1}{$a_{02}$} & \bitbox{1}{$a_{03}$} & \bitbox{1}{$a_{10}$} & \bitbox{1}{$a_{11}$} & \bitbox{1}{$a_{12}$} & \bitbox{1}{$a_{13}$}
\end{bytefield}

All elements are flat; there are only two primitive types: 64-bit integers and 64-bit floats. Arrays of tuples are supported but not arrays of tuples of arrays; there are no user-defined types. Arrays of arrays are treated as higher-dimensional arrays. These limitations are typical of array languages and are enough for nontrivial computation, for instance neural networks.

Such constraints, with extra bookkeeping information added during IR generation, are responsible for the surprising fact that memory allocation can be completely determined at compile time.

\section{Method}

\subsection{Compiler Pipeline}

Our work is based on established liveness algorithms; we define {\tt uses} and {\tt defs} on statements (in terms of arrays), compute liveness \cite[pp.~213-216]{appel1998}, and then construct live intervals \cite{poletto1999}.

\tikzset{
block/.style = {draw, minimum height=2.5em, minimum width=4em, node distance=1.75cm}
}

\begin{tikzpicture}[auto]
    \node [] (expr) {\ldots};
    \node [block, below of=expr] (plain) {\tt [Stmt]};
    \node [block, below of=plain] (live) {\tt [(Stmt, Liveness)]};
    \node [block, below of=live] (alloc) {\tt [Stmt]};
    \draw [->] (expr) -- node {IR Generation} (plain);
    \draw [->] (plain) -- node {Liveness Analysis} (live);
    \draw [->] (live) -- node {Insert Frees} (alloc);
\end{tikzpicture}

The IR used in the Apple compiler is sequences of statements and expressions, viz.

\begin{verbatim}
data Exp = Const Int
         | Reg Temp
         | At ArrayPtr
         ...

data Stmt = MovTemp Temp Exp
          | Write ArrayPtr Exp
          -- label, register, size
          | Malloc Lbl Temp Exp
          | CondJump Exp Loc
          | Jump Loc | Label Loc
          | Free Temp
          ...
\end{verbatim}

Expressions can read from memory via {\tt At} and {\tt Stmt}s make use of memory access for writes, allocations etc. A function

\begin{verbatim}
aeval :: Expr -> IRM (Temp, Lbl, [Stmt])
\end{verbatim}
translates an array expression, assigning a {\tt Lbl} for subsequent access and associating the labeled array with a {\tt Temp} to be used to free it.

All accesses to an array use an {\tt ArrayPtr}, which specifies the {\tt Lbl} for tracking within the compiler. In this way we avoid being confounded by multiple pointers to the same array. 

\begin{verbatim}
-- register, offset, label
data ArrayPtr = ArrayPtr Temp (Maybe Exp) Lbl
\end{verbatim}

Recall that references are not supported, so it is impossible for an array access to keep another array live.

Then we have:

\begin{verbatim}
defs :: Stmt -> Set Lbl
defs (Malloc l _ e) = singleton l
defs _              = empty

uses :: Stmt -> Set Lbl
uses (Write (ArrayPtr _ _ l) e) =
    insert l (defsE e)
uses ...
\end{verbatim}

By tracking arrays via these labels, one can access the array from different {\tt Temp}s; this is necessary for generating efficient code.

After liveness analysis, we have liveness information for each {\tt Stmt}, viz.

\begin{verbatim}
data Liveness =
  Liveness { ins :: Set Lbl, outs :: Set Lbl }
\end{verbatim}

With this we compute live intervals for each {\tt Lbl}, as in the literature \cite{poletto1999}.

We then insert a {\tt free} when the live interval for an array ends by looking up the {\tt Temp} associated with the {\tt Lbl}.

\subsection{Generation}

We must take care when arranging loops; the loop should exit by continuing rather than jumping to an exit location. This ensures that the {\tt free}s inserted at the end of live intervals are always reachable.

For instance, we do not write:

\begin{verbatim}
apple_0:
(condjump (< (reg r_2) (int 2)) apple_1)
(movtemp r_0
  @(ptr r_1+(+ (asl (reg r_2) (int 3)) (int 16))))
(jump apple_0)

apple_1:
\end{verbatim}

But rather:

\begin{verbatim}
(condjump (>= (reg r_2) (int 2)) apple_1)

apple_0:
(movtemp r_0
  @(ptr r_1+(+ (asl (reg r_2) (int 3)) (int 16))))
(condjump (< (reg r_2) (int 2) apple_0)

apple_1:
\end{verbatim}

Had we written the former, the {\tt free} would be unreachable, viz.

\begin{verbatim}
apple_0:
(condjump (< (reg r_2) (int 2)) apple_1)
(movtemp r_0
  @(ptr r_1+(+ (asl (reg r_2) (int 3)) (int 16))))
(jump apple_0)
(free r_2)

apple_1:
\end{verbatim}

This is not the case with the latter:

\begin{verbatim}
(condjump (>= (reg r_2) (int 2)) apple_1)

apple_0:
(movtemp r_0
  @(ptr r_1+(+ (asl (reg r_2) (int 3)) (int 16))))
(condjump (< (reg r_2) (int 2) apple_0)
(free r_2)

apple_1:
\end{verbatim}

Since jumps are only generated by the compiler in a few cases, we can guarantee that generated code is correct by being careful.

\section{Embeddings}

% https://numpy.org/doc/stable/reference/c-api/array.html#
The Apple JIT has been embedded in Python as an extension module \cite{pythonext}. Observe the following interaction:

\begin{verbatim}
>>> import apple
>>> area=apple.jit('''
λas.λbs.
    { Σ ⇐ [(+)/x]
    ; 0.5*abs.(Σ ((*)`as (1⊖bs))
        - Σ ((*)`(1⊖as) bs))
    }
''')
>>> import numpy as np
>>> apple.f(area,
    np.array([0,0,3.]),
    np.array([0,4,4.]))
6.0
\end{verbatim}

There are wrappers for calling the JIT from R as well \cite{wickham}:

\begin{verbatim}
> shoelace<-jit("
λas.λbs.
    { Σ ⇐ [(+)/x]
    ; 0.5*abs.(Σ ((*)`as (1⊖bs))
        - Σ ((*)`(1⊖as) bs))
    }
")
> run(shoelace,c(0,0,3),c(0,4,4))
[1] 6
\end{verbatim}

Thus we can run Apple code on NumPy arrays and R vectors without frustrating the garbage collector.

We can also compile to an object file and then call from C, viz.

\begin{verbatim}
#include<stdio.h>
#include<stdlib.h>
#include<string.h>

typedef double F;typedef int64_t I;
typedef void* U;

#define V(n,xs,p) \
  { \
    p=malloc(16+8*n); \
    I* i_p=p;*i_p=1;i_p[1]=n; \
    memcpy(p+16,xs,8*n); \
  }

extern F shoelace(U, U);

int main(int argc, char *argv[]) {
    F xs[] = {0,4,4};
    F ys[] = {0,0,3};
    U x; V(3,xs,x);
    U y; V(3,ys,y);
    printf("%f\n", shoelace(x,y));
    free(x);free(y);
}
\end{verbatim}

Thus Apple code works with languages such as C with more primitive provisions.

\section{Coda}

Apple has the potential to be far more efficient; one could consolidate allocations, e.g.

\begin{verbatim}
 irange 0 20 1 ++ irange 0 10 1
\end{verbatim}
performs one allocation for each {\tt irange} but this could be consolidated into one---{\tt irange 0 20 1} is inferred to have type {\tt Vec 20 int} in the existing compiler; with liveness and size information one could allot arrays whose live intervals do not overlap to the same location in memory.

This constrained high-level language occupies a sweet spot in compilers: because we control IR generation, we can do analyses that would be thwarted by pointer aliasing in C, and because we do not support references we simplify tracking.

\bibliographystyle{ACM-Reference-Format}
\bibliography{alloc.bib}

\end{document}
