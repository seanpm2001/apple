%! TeX program = lualatex

\documentclass[sigplan,screen,anonymous]{acmart}

\usepackage{fontspec}
\usepackage{bytefield}
\usepackage{tikz}
\usepackage{hyperref}
\usepackage{url}
\usepackage{mdframed}

\begin{document}

% https://mirror.math.princeton.edu/pub/CTAN/macros/unicodetex/latex/fontspec/fontspec.pdf
\setmonofont{Jet Brains Mono}[Scale=MatchAveragecase]

% https://mirrors.mit.edu/CTAN/macros/latex/contrib/mdframed/mdframed.pdf
\newmdenv[
  linecolor=blue,
  linewidth=2pt,
  topline=false,
  bottomline=false,
  rightline=false,
  leftline=true,
  skipabove=0,
  skipbelow=0,
  innertopmargin=0,
  innerbottommargin=0,
  innerleftmargin=0,
]{live}

% export functions, not "calls into an array system"

\begin{abstract}
    Here we present statically determined memory allocation for flat, immutable arrays used in the Apple array system, a compiler for an expression-oriented functional language.
    % TODO: basically put results first
    Array languages like J and APL suffer from a lack of embedability in implementations. Adroit memory management can make embedding easier; one would like to avoid thinking about ownership across two garbage collectors.
    Arrays are usable as pointers, with no dependence on a garbage collector.
    Ownership is simple and Apple code does not constrain memory management in the host language.
    Two embeddings---one in Python and one in R---are exhibited.
\end{abstract}

\title{Apple Array Allocation}
\orcid{0000-0001-6093-2967}
\author{V. E. McHale}
\affiliation{%
\institution{Northern Trust}
  \streetaddress{50 South LaSalle Street}
  \city{Chicago}
  \state{IL}
  \postcode{60603}
  \country{USA}
}
\email{vamchale@gmail.com}
\maketitle

\section{Introduction}

Array languages such as APL and J suffer from undeserved obscurity \cite{hsu2023}. In order to make them more useful to enthusiasts, one might hope to embed them, thus providing access to libraries. % , providing users with the facilities of libraries such as matplotlib.

% conversely, array languages are good candidates for a new style of compiler because

APL implementations typically use reference-counting \cite[p.~47]{hui2020} for performance reasons, but this imposes on the calling code---one must increment the reference count and delegate each array to a garbage collector.

\subsection{Background}
% introduce APL/J first then C?

Rather than comparing to competitors such as NumPy \cite{harris2020}, we take inspiration from C---we would like an array language that does not impose on its host language \cite{kell2017}.
C is almost vulgar in offering pointers as arrays; the typical APL implementation uses reference-counting \cite[p.~47]{hui2020} for performance reasons.

By compiling high-level array expressions to a C procedure with all allocations and frees predetermined, we reduce the demands of calling Apple code in other environments.

% background: sad case of .NET/APL,
% J: "server" API depends on global state

% also show off matplotlib
% actually fairly burdensome to have each be a reference counter, also not all languages have an RC garbage collector!
%
% insight: it is precisely because it is high-level that this works...

\subsection{Apple Array System}

The Apple JIT compiler is a function
\begin{verbatim}
apple_compile :: ( FunPtr (CSize -> Ptr a)
                 , FunPtr (Ptr a -> ())
                 )
              -> String -> Bytes
\end{verbatim}
taking a pointer to {\tt malloc}, a pointer to {\tt free}, and source code as input and returning machine code; the compiler only generates these two foreign function calls and there is no runtime system.

This simplifies linking in the JIT. % only makes two ffi calls.

% Converse: array languages are a good place to try out new compiler architectures!

\subsubsection{Flat Array Types}

Apple arrays are completely flat in memory, consisting of rank, dimensions, and data laid out contiguously.

A {\tt 2x4} array:

\begin{bytefield}[bitwidth=0.075\linewidth]{11}
    \\
    \bitheader{0-10} \\
    \bitbox{1}{2} & \bitbox{1}{2} & \bitbox{1}{4} & \bitbox{1}{$a_{00}$} & \bitbox{1}{$a_{01}$} & \bitbox{1}{$a_{02}$} & \bitbox{1}{$a_{03}$} & \bitbox{1}{$a_{10}$} & \bitbox{1}{$a_{11}$} & \bitbox{1}{$a_{12}$} & \bitbox{1}{$a_{13}$}
\end{bytefield}

All elements are flat; there are only two primitive types: 64-bit integers and 64-bit floats. Arrays of tuples are supported but not arrays of tuples of arrays; there are no user-defined types. Arrays of arrays are treated as higher-dimensional arrays.

% no recursion

Such constraints, with extra bookkeeping information added during IR generation, are responsible for the surprising fact that memory allocation can be completely determined at compile time.
Though such limited types may seem spartan to a functional programmer, this is enough to stand toe-to-toe with NumPy. % and enough for machine learning

\subsubsection{Language}

The language does not support recursion; all looping is implicit via maps, folds, etc. This is hardly

\section{Method}

\subsection{Compiler Pipeline}

Our work is based on established liveness algorithms; we define {\tt uses} and {\tt defs} on statements (in terms of arrays), compute liveness \cite[pp.~213-216]{appel1998}, and then construct live intervals \cite{poletto1999}.

\tikzset{
block/.style = {draw, minimum height=2.5em, minimum width=4em, node distance=1.75cm}
}

\begin{tikzpicture}[auto]
    \node [] (expr) {\ldots};
    \node [block, below of=expr] (plain) {\tt [Stmt]};
    \node [block, below of=plain] (live) {\tt [(Stmt, Liveness)]};
    \node [block, below of=live] (alloc) {\tt [Stmt]};
    \draw [->] (expr) -- node {IR Generation} (plain);
    \draw [->] (plain) -- node {Liveness Analysis} (live);
    \draw [->] (live) -- node {Insert Frees} (alloc);
\end{tikzpicture}

The IR used in the Apple compiler is sequences of statements and expressions, viz.

\begin{verbatim}
data Exp = Const Int
         | Reg Temp
         | At ArrayPtr
         ...

data Stmt = MovTemp Temp Exp
          | Write ArrayPtr Exp
          | Malloc Lbl Temp Exp -- label, register, size
          | CondJump Exp Loc
          | Jump Loc | Label Loc
          | Free Temp
          ...
\end{verbatim}

Expressions can read from memory via {\tt At} and {\tt Stmt}s make use of memory access for writes, allocations etc. A function

\begin{verbatim}
aeval :: Expr -> IRM (Temp, Lbl, [Stmt])
\end{verbatim}
translates an array expression, assigning a {\tt Lbl} for subsequent access and associating the labeled array with a {\tt Temp} to be used to free it.

All accesses to an array use an {\tt ArrayPtr}, which specifies the {\tt Lbl} for tracking within the compiler.

\begin{verbatim}
-- register, offset, label
data ArrayPtr = ArrayPtr Temp (Maybe Exp) Lbl
\end{verbatim}

Then we have:

\begin{verbatim}
defs :: Stmt -> Set Lbl
defs (Malloc l _ e) = singleton l
defs _              = empty

uses :: Stmt -> Set Lbl
uses (Write (ArrayPtr _ _ l) e) = insert l (defsE e)
uses ...
\end{verbatim}

% https://www.cs.rice.edu/~kvp1/spring2008/lecture7.pdf

Note that with such labels one can access the array from different {\tt Temp}s; this is necessary for generating efficient code.

% With {\tt defs} and {\tt uses} thus defined, we compute live intervals for {\tt Stmt}s \cite{poletto1999}.

After liveness analysis, we have liveness information for each {\tt Stmt}, viz.

% TODO: redo this section to not repeat the above ^
% maybe introduce per-array tracking/temps before?

\begin{verbatim}
data Liveness =
  Liveness { ins :: Set Lbl, outs :: Set Lbl }
\end{verbatim}

Then we can define {\tt done :: Stmt -> Set Lbl} for each array as the last {\tt Stmt} for which

We then insert a {\tt free} when the live interval for an array ends. Since liveness is tracked per-array, we look up the {\tt Temp}

\subsection{Generation}

We must take care when arranging loops; the loop should exit by continuing rather than jumping to an exit location. This ensures that the {\tt free}s inserted at the end of live intervals are always reachable.

For instance, we do not write:

\begin{verbatim}
apple_0:
(condjump (< (reg r_2) (int 2)) apple_1)
(movtemp r_0
  @(ptr r_1+(+ (asl (reg r_2) (int 3)) (int 16))))
(jump apple_0)

apple_1:
\end{verbatim}

But rather:

\begin{verbatim}
(condjump (>= (reg r_2) (int 2)) apple_1)

apple_0:
(movtemp r_0
  @(ptr r_1+(+ (asl (reg r_2) (int 3)) (int 16))))
(condjump (< (reg r_2) (int 2) apple_0)

apple_1:
\end{verbatim}

Had we written the former, the {\tt free} would be unreachable, viz.

\begin{verbatim}
apple_0:
(condjump (< (reg r_2) (int 2)) apple_1)
(movtemp r_0
  @(ptr r_1+(+ (asl (reg r_2) (int 3)) (int 16))))
(jump apple_0)
(free r_2)

apple_1:
\end{verbatim}

This is not the case with the latter:

\begin{verbatim}
(condjump (>= (reg r_2) (int 2)) apple_1)

apple_0:
(movtemp r_0
  @(ptr r_1+(+ (asl (reg r_2) (int 3)) (int 16))))
(condjump (< (reg r_2) (int 2) apple_0)
(free r_2)

apple_1:
\end{verbatim}

Since jumps are only generated by the compiler in a few cases, we can guarantee that generated code is correct by being careful.

\section{Embeddings}

Apple has been embedded in Python and R. Observe the following interactions:

\begin{verbatim}
>>> import apple
>>> area=apple.jit('''
λas.λbs.
    { Σ ⇐ [(+)/x]
    ; 0.5*abs.(Σ ((*)`as (1⊖bs)) - Σ ((*)`(1⊖as) bs))
    }
''')
>>> import numpy as np
>>> apple.f(area,np.array([0,0,3.]),np.array([0,4,4.]))
6.0
\end{verbatim}

\begin{verbatim}
> shoelace<-jit("
λas.λbs.
    { Σ ⇐ [(+)/x]
    ; 0.5*abs.(Σ ((*)`as (1⊖bs)) - Σ ((*)`(1⊖as) bs))
    }
")
> run(shoelace,c(0,0,3),c(0,4,4))
[1] 6
\end{verbatim}

Thus we can run Apple code on NumPy arrays and R vectors without frustrating the garbage collector.

Apple code can be called from C, viz.

\begin{verbatim}
#include <stdio.h>
#include <stdlib.h>

#define R return
#define DO(i,n,a) {I i;for(i=0;i<n;i++){a;}}

typedef double F;typedef int64_t I; typedef void* U;

typedef struct Af {I rnk; I* dim; F* xs;} Af;

U poke_af (Af x) {
    I rnk = x.rnk;
    I t = 1;
    DO(i,rnk,t*=x.dim[i]);
    U p = malloc(8+8*x.rnk+8*t);
    I* i_p = p;F* f_p = p;
    *i_p = rnk;
    DO(i,rnk,i_p[i+1]=x.dim[i]);
    DO(i,t,f_p[i+1+rnk]=x.xs[i]);
    R p;
}

extern F shoelace(U, U);

int main(int argc, char *argv[]) {
    F xs[] = {0,4,4};
    F ys[] = {0,0,3};
    I d[] = {3};
    Af a = {1,d,xs};
    Af b = {1,d,ys};
    U x = poke_af(a);U y = poke_af(b);
    printf("%f\n", shoelace(x,y));
    free(x);free(y);
}
\end{verbatim}

Thus Apple code works with garbage collected languages and languages such as C with more primitive provisions.

\section{Coda}

Apple has the potential to be far more efficient; one could consolidate allocations, e.g.

\begin{verbatim}
 irange 0 20 1 ++ irange 0 10 1
\end{verbatim}
performs one allocation for each {\tt irange} but this could be consolidated into one---{\tt irange 0 20 1} is inferred to have type {\tt Vec 20 int} in the existing compiler; with liveness and size information one could do something like linear register allocation in which arrays are assigned to memory slots. % Possible because we are in a high-level language

This vindicates flat arrays; while banning arrays of functions \&c. may not be obvious to a functional programmer, studying this particular set of constraints has potential; one could use it to implement a compiler for a high-level language that produces performant and portable code.

\bibliographystyle{ACM-Reference-Format}
\bibliography{alloc.bib}

\end{document}
