%! TeX program = lualatex

\documentclass[sigplan,screen]{acmart}

\usepackage{bytefield}
\usepackage{tikz}
\usepackage{hyperref}
\usepackage{url}

\begin{document}

% https://mirror.math.princeton.edu/pub/CTAN/macros/unicodetex/latex/fontspec/fontspec.pdf
\setmonofont{Jet Brains Mono}[Scale=MatchAveragecase]

% emphasize embedability as motivation (lack of popularity of APL, shocking popularity of Python... futhark/accelerate)
% Then show that the method allows our own constructs hm

% export functions, not "calls into an array system"

\begin{abstract}
    Array languages like J and APL suffer from a lack of embedability in implementations. Adroit memory management can make embedding easier; one would like to avoid thinking about ownership across two garbage collectors.
    Here we present statically determined memory allocation used in the Apple array system, a compiler for a high-level, expression-oriented functional language.
    Arrays are usable as pointers, with no dependence on a garbage collector.
    Ownership is simple and Apple code does not constrain memory management in the host language.
    Two embeddings---one in Python and one in R---attest to the feasibility of this method.
\end{abstract}

\title{Apple Array Allocation}
\orcid{0000-0001-6093-2967}
\author{V. E. McHale}
\affiliation{%
\institution{Northern Trust}
  \streetaddress{50 South LaSalle Street}
  \city{Chicago}
  \state{IL}
  \postcode{60603}
  \country{USA}
}
\email{vamchale@gmail.com}
\maketitle

\section{Introduction}

Array languages such as APL and J suffer from undeserved obscurity \cite{hsu2023}. In order to make wider use of array languages, one might hope to embded them. So we look to C---we would like an array language that does not impose on its host language \cite{kell2017}.
C is almost vulgar in offering pointers as arrays; the typical APL implementation uses reference-counting \cite[p.~47]{hui2020} for performance reasons. But this means that arrays depend on a garbage collector running alongside to behave sensibly. By compiling high-level array expressions to a C procedure, without any expectation of a garbage collector being set up or tied in, we reduce the burden to using our code from other environments.

\section{Method}

\subsection{Flat Array Types}

Apple arrays are completely flat in memory, consisting of rank, dimensions, and data laid out contiguously.

A {\tt 2x4} array:

\begin{bytefield}[bitwidth=0.075\linewidth]{11}
    \\
    \bitheader{0-10} \\
    \bitbox{1}{2} & \bitbox{1}{2} & \bitbox{1}{4} & \bitbox{1}{$a_{00}$} & \bitbox{1}{$a_{01}$} & \bitbox{1}{$a_{02}$} & \bitbox{1}{$a_{03}$} & \bitbox{1}{$a_{10}$} & \bitbox{1}{$a_{11}$} & \bitbox{1}{$a_{12}$} & \bitbox{1}{$a_{13}$}
\end{bytefield}

All data are flat; there are only two primitive types: 64-bit integers and 64-bit floats. Arrays of tuples are supported but not arrays of tuples of arrays; there are no user-defined types.

Such constraints, with extra bookkeeping information added during IR generation, are responsible for the surprising fact that memory allocation can be completely determined at compile time. Though they may seem spartan to a functional programmer, this is enough to stand toe-to-toe with NumPy.

\subsection{Compiler Pipeline}

Our work is based on established liveness algorithms; we annotate statements with {\tt uses} and {\tt defs} and thence compute liveness intervals for arrays.
% control flow

\tikzset{
block/.style = {draw, minimum height=2.5em, minimum width=4em, node distance=1.75cm}
}

\begin{tikzpicture}[auto]
    \node [] (expr) {\ldots};
    \node [block, below of=expr] (plain) {\tt [Stmt]};
    \node [block, below of=plain] (live) {\tt [(Stmt, Liveness)]};
    \node [block, below of=live] (alloc) {\tt [Stmt]};
    \draw [->] (expr) -- node {IR Generation} (plain);
    \draw [->] (plain) -- node {Liveness Analysis} (live);
    \draw [->] (live) -- node {Insert Frees} (alloc);
\end{tikzpicture}

% We insert {\tt free}s mechanically, % frees are calculated and thence less fickle (double free/leftover)
% allocations are specified but not frees...

The IR used in the Apple compiler is sequences of statements and expressions, viz.

\begin{verbatim}
data Exp = Const Int
         | Reg Temp
         | At ArrayPtr
         ...

data Stmt = MovTemp Temp Exp
          | Write ArrayPtr Exp
          | Malloc Lbl Temp Exp -- label, register, size
          | CondJump Exp Loc
          | Jump Loc | Label Loc
          | Free Temp
          ...
\end{verbatim}

Expressions can read from memory via {\tt At} and {\tt Stmt}s make use of memory access for writes, allocations etc. A function

\begin{verbatim}
aeval :: Expr -> IRM (Temp, Lbl, [Stmt])
\end{verbatim}
translates an array expression, assigning a {\tt Lbl} for subsequent access and associating the labeled array with a {\tt Temp} to be used to free it.

% When generating the IR, we track each mention of the array with a label and associate the label with the temporary that can be used to free it.
All accesses to an array use the {\tt ArrayPtr} type, which specifies the {\tt Lbl} for tracking within the compiler.

\begin{verbatim}
-- register, offset, label
data ArrayPtr = ArrayPtr Temp (Maybe Exp) Lbl
\end{verbatim}

Then one has

\begin{verbatim}
defs :: Stmt -> IntSet
defs (Malloc l _ e) = singleton l
defs _              = empty

uses :: Stmt -> IntSet
uses (Write (ArrayPtr _ _ l) e) = insert l (defsE e)
uses ...
\end{verbatim}

% https://www.cs.rice.edu/~kvp1/spring2008/lecture7.pdf

Note that with such labels one can access the array from different {\tt Temp}s; this is necessary for generating efficient code in the compiler.

With {\tt defs} and {\tt uses} thus defined, we compute liveness intervals for {\tt Stmt}s \cite{poletto1999}.

\begin{verbatim}
data Liveness =
  Liveness { done :: IntSet, new :: IntSet }
\end{verbatim}

For each {\tt (Stmt, Liveness)}, when we encounter a label in the {\tt done} set, we look up the {\tt Temp} to free it and insert a {\tt free} statement.

\subsection{Generation}

We must take care when arranging loops; the loop should exit by continuing rather than jumping to an exit location. This ensures that the {\tt free}s inserted at the end of live intervals are always reachable.

For instance, we do not write:

\begin{verbatim}
apple_0:
(condjump (< (reg r_2) (int 2)) apple_1)
(movtemp r_0
    @(ptr r_1+(+ (asl (reg r_2) (int 3)) (int 16))))
(jump apple_0)

apple_1:
\end{verbatim}

But rather:

\begin{verbatim}
(condjump (>= (reg r_2) (int 2)) apple_1)

apple_0:
(movtemp r_0
    @(ptr r_1+(+ (asl (reg r_2) (int 3)) (int 16))))
(condjump (< (reg r_2) (int 2) apple_0)

apple_1:
\end{verbatim}

Had we written the former, the {\tt free} would be unreachable, viz.

\begin{verbatim}
apple_0:
(condjump (< (reg r_2) (int 2)) apple_1)
(movtemp r_0
    @(ptr r_1+(+ (asl (reg r_2) (int 3)) (int 16))))
(jump apple_0)
(free r_2)

apple_1:
\end{verbatim}

This is not the case with the latter:

\begin{verbatim}
(condjump (>= (reg r_2) (int 2)) apple_1)

apple_0:
(movtemp r_0
    @(ptr r_1+(+ (asl (reg r_2) (int 3)) (int 16))))
(condjump (< (reg r_2) (int 2) apple_0)
(free r_2)

apple_1:
\end{verbatim}

Since jumps are only generated by the compiler in a few cases, we can guarantee that the generated code is correct by being careful.

\section{Embeddings}

Apple has been embedded in Python and R. See the following interactions:

\begin{verbatim}
>>> import apple
>>> area=apple.cache('''
λas.λbs.
    { Σ ⇐ [(+)/x]
    ; 0.5*abs.(Σ ((*)`as (1⊖bs)) - Σ ((*)`(1⊖as) bs))
    }
''')
>>> import numpy as np
>>> apple.f(area,np.array([0,0,3.]),np.array([0,4,4.]))
6.0
\end{verbatim}

\begin{verbatim}
> source("./apple.R")
> shoelace<-cache("
λas.λbs.
    { Σ ⇐ [(+)/x]
    ; 0.5*abs.(Σ ((*)`as (1⊖bs)) - Σ ((*)`(1⊖as) bs))
    }
")
> run(shoelace,c(0,0,3),c(0,4,4))
[1] 6
\end{verbatim}

Thus we can run Apple code on NumPy arrays and R vectors without frustrating the garbage collector.

\section{Coda}

Apple has the potential to be far more efficient; one could consolidate allocations, e.g.

\begin{verbatim}
 irange 0 20 1 ++ irange 0 10 1
\end{verbatim}
performs one allocation for each {\tt irange} but this could be consolidated into one---{\tt irange 0 20 1} is inferred to have type {\tt Vec 20 int} in the existing compiler; with liveness and size information one could do something like linear register allocation in which arrays are assigned to memory slots.

This is an advantage of completely flat arrays. This style of constraints on
% That one can get such performance without reference counting
% worthwhile to carve out this limited arrays

\bibliographystyle{ACM-Reference-Format}
\bibliography{alloc.bib}

\end{document}
