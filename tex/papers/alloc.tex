%! TeX program = lualatex

\documentclass[acmsmall,screen,anonymous,nonacm]{acmart}

\usepackage{bytefield}
\usepackage{tikz}
\usepackage{hyperref}
\usepackage{url}

\begin{document}

% https://mirror.math.princeton.edu/pub/CTAN/macros/unicodetex/latex/fontspec/fontspec.pdf
\setmonofont{Jet Brains Mono}[Scale=MatchAveragecase]

% export functions, not "calls into an array system"

\begin{abstract}
    Array languages like J and APL suffer from a lack of embedability in implementations. Adroit memory management can make embedding easier; one would like to avoid thinking about ownership across two garbage collectors.
    Here we present statically determined memory allocation for flat, immutable arrays used in the Apple array system, a compiler for an expression-oriented functional language.
    Arrays are usable as pointers, with no dependence on a garbage collector.
    Ownership is simple and Apple code does not constrain memory management in the host language.
    Two embeddings---one in Python and one in R---are exhibited.
\end{abstract}

\title{Apple Array Allocation}
\orcid{0000-0001-6093-2967}
\author{V. E. McHale}
\affiliation{%
\institution{Northern Trust}
  \streetaddress{50 South LaSalle Street}
  \city{Chicago}
  \state{IL}
  \postcode{60603}
  \country{USA}
}
\email{vamchale@gmail.com}
\maketitle

\section{Introduction}

Array languages such as APL and J suffer from undeserved obscurity \cite{hsu2023}. In order to make wider use of array languages, one might hope to embed them. % , providing users with the facilities of libraries such as matplotlib.

\subsection{Background}

Rather than comparing to competitors such as NumPy \cite{harris2020}, we look to C---we would like an array language that does not impose on its host language \cite{kell2017}.
C is almost vulgar in offering pointers as arrays; the typical APL implementation uses reference-counting \cite[p.~47]{hui2020} for performance reasons. But this means that arrays depend on a garbage collector running alongside to behave sensibly. By compiling high-level array expressions to a C procedure with all allocations and frees predetermined, we reduce the demands of calling Apple code in other environments.

\begin{tabular}{r|c|c|c}
  \hline
  & Input & Array & Exposed Function \\ \hline
  C & Sequence of steps & Pointer & ELF binary \\
  J & Expression & Reference-counted & Action in environment \\
\end{tabular}

% background: sad case of .NET/APL,
% J: "server" API depends on global state

% also show off matplotlib

\subsection{Apple Array System}

The Apple compiler

% simplifies runtime linking

\section{Method}

\subsection{Flat Array Types}

Apple arrays are completely flat in memory, consisting of rank, dimensions, and data laid out contiguously.

A {\tt 2x4} array:

\begin{bytefield}[bitwidth=0.075\linewidth]{11}
    \\
    \bitheader{0-10} \\
    \bitbox{1}{2} & \bitbox{1}{2} & \bitbox{1}{4} & \bitbox{1}{$a_{00}$} & \bitbox{1}{$a_{01}$} & \bitbox{1}{$a_{02}$} & \bitbox{1}{$a_{03}$} & \bitbox{1}{$a_{10}$} & \bitbox{1}{$a_{11}$} & \bitbox{1}{$a_{12}$} & \bitbox{1}{$a_{13}$}
\end{bytefield}

All data are flat; there are only two primitive types: 64-bit integers and 64-bit floats. Arrays of tuples are supported but not arrays of tuples of arrays; there are no user-defined types.

% no recursion...

Such constraints, with extra bookkeeping information added during IR generation, are responsible for the surprising fact that memory allocation can be completely determined at compile time. Though sucgh limited types may seem spartan to a functional programmer, this is enough to stand toe-to-toe with NumPy. % and enough for machine learning

% cases

\subsection{Compiler Pipeline}

Our work is based on established liveness algorithms; we annotate statements with {\tt uses} and {\tt defs} and thence compute liveness intervals \cite{poletto1999} for arrays.
% cite appel

\tikzset{
block/.style = {draw, minimum height=2.5em, minimum width=4em, node distance=1.75cm}
}

\begin{tikzpicture}[auto]
    \node [] (expr) {\ldots};
    \node [block, below of=expr] (plain) {\tt [Stmt]};
    \node [block, below of=plain] (live) {\tt [(Stmt, Liveness)]};
    \node [block, below of=live] (alloc) {\tt [Stmt]};
    \draw [->] (expr) -- node {IR Generation} (plain);
    \draw [->] (plain) -- node {Liveness Analysis} (live);
    \draw [->] (live) -- node {Insert Frees} (alloc);
\end{tikzpicture}

The IR used in the Apple compiler is sequences of statements and expressions, viz.

\begin{verbatim}
data Exp = Const Int
         | Reg Temp
         | At ArrayPtr
         ...

data Stmt = MovTemp Temp Exp
          | Write ArrayPtr Exp
          | Malloc Lbl Temp Exp -- label, register, size
          | CondJump Exp Loc
          | Jump Loc | Label Loc
          | Free Temp
          ...
\end{verbatim}

Expressions can read from memory via {\tt At} and {\tt Stmt}s make use of memory access for writes, allocations etc. A function

\begin{verbatim}
aeval :: Expr -> IRM (Temp, Lbl, [Stmt])
\end{verbatim}
translates an array expression, assigning a {\tt Lbl} for subsequent access and associating the labeled array with a {\tt Temp} to be used to free it.

All accesses to an array use the {\tt ArrayPtr} type, which specifies the {\tt Lbl} for tracking within the compiler.

\begin{verbatim}
-- register, offset, label
data ArrayPtr = ArrayPtr Temp (Maybe Exp) Lbl
\end{verbatim}

Then one has

\begin{verbatim}
defs :: Stmt -> IntSet
defs (Malloc l _ e) = singleton l
defs _              = empty

uses :: Stmt -> IntSet
uses (Write (ArrayPtr _ _ l) e) = insert l (defsE e)
uses ...
\end{verbatim}

% https://www.cs.rice.edu/~kvp1/spring2008/lecture7.pdf

Note that with such labels one can access the array from different {\tt Temp}s; this is necessary for generating efficient code in the compiler.

With {\tt defs} and {\tt uses} thus defined, we compute liveness intervals for {\tt Stmt}s \cite{poletto1999}.

\begin{verbatim}
data Liveness =
  Liveness { done :: IntSet, new :: IntSet }
\end{verbatim}

For each {\tt (Stmt, Liveness)}, when we encounter a label in the {\tt done} set, we look up the {\tt Temp} to free it and insert a {\tt free} statement.

\subsection{Generation}

We must take care when arranging loops; the loop should exit by continuing rather than jumping to an exit location. This ensures that the {\tt free}s inserted at the end of live intervals are always reachable.

For instance, we do not write:

\begin{verbatim}
apple_0:
(condjump (< (reg r_2) (int 2)) apple_1)
(movtemp r_0
    @(ptr r_1+(+ (asl (reg r_2) (int 3)) (int 16))))
(jump apple_0)

apple_1:
\end{verbatim}

But rather:

\begin{verbatim}
(condjump (>= (reg r_2) (int 2)) apple_1)

apple_0:
(movtemp r_0
    @(ptr r_1+(+ (asl (reg r_2) (int 3)) (int 16))))
(condjump (< (reg r_2) (int 2) apple_0)

apple_1:
\end{verbatim}

Had we written the former, the {\tt free} would be unreachable, viz.

\begin{verbatim}
apple_0:
(condjump (< (reg r_2) (int 2)) apple_1)
(movtemp r_0
    @(ptr r_1+(+ (asl (reg r_2) (int 3)) (int 16))))
(jump apple_0)
(free r_2)

apple_1:
\end{verbatim}

This is not the case with the latter:

\begin{verbatim}
(condjump (>= (reg r_2) (int 2)) apple_1)

apple_0:
(movtemp r_0
    @(ptr r_1+(+ (asl (reg r_2) (int 3)) (int 16))))
(condjump (< (reg r_2) (int 2) apple_0)
(free r_2)

apple_1:
\end{verbatim}

Since jumps are only generated by the compiler in a few cases, we can guarantee that the generated code is correct by being careful.

\section{Embeddings}

Apple has been embedded in Python and R. Observe the following interactions:

\begin{verbatim}
>>> import apple
>>> area=apple.jit('''
λas.λbs.
    { Σ ⇐ [(+)/x]
    ; 0.5*abs.(Σ ((*)`as (1⊖bs)) - Σ ((*)`(1⊖as) bs))
    }
''')
>>> import numpy as np
>>> apple.f(area,np.array([0,0,3.]),np.array([0,4,4.]))
6.0
\end{verbatim}

\begin{verbatim}
> source("./apple.R")
> shoelace<-jit("
λas.λbs.
    { Σ ⇐ [(+)/x]
    ; 0.5*abs.(Σ ((*)`as (1⊖bs)) - Σ ((*)`(1⊖as) bs))
    }
")
> run(shoelace,c(0,0,3),c(0,4,4))
[1] 6
\end{verbatim}

Thus we can run Apple code on NumPy arrays and R vectors without frustrating the garbage collector.

Apple code can be called from C on its own terms, unlike NumPy or J, viz.

\begin{verbatim}
#include <stdio.h>
#include <stdlib.h>

#define R return
#define DO(i,n,a) {I i;for(i=0;i<n;i++){a;}}

typedef double F;typedef int64_t I; typedef void* U;

typedef struct Af {I rnk; I* dim; F* xs;} Af;

U poke_af (Af x) {
    I rnk = x.rnk;
    I t = 1;
    DO(i,rnk,t*=x.dim[i]);
    U p = malloc(8+8*x.rnk+8*t);
    I* i_p = p;F* f_p = p;
    *i_p = rnk;
    DO(i,rnk,i_p[i+1]=x.dim[i]);
    DO(i,t,f_p[i+1+rnk]=x.xs[i]);
    R p;
}

extern F shoelace(U, U);

int main(int argc, char *argv[]) {
    F xs[] = {0,4,4};
    F ys[] = {0,0,3};
    I d[] = {3};
    Af a = {1,d,xs};
    Af b = {1,d,ys};
    U x = poke_af(a);U y = poke_af(b);
    printf("%f\n", shoelace(x,y));
    free(x);free(y);
}
\end{verbatim}

\section{Coda}

Apple has the potential to be far more efficient; one could consolidate allocations, e.g.

\begin{verbatim}
 irange 0 20 1 ++ irange 0 10 1
\end{verbatim}
performs one allocation for each {\tt irange} but this could be consolidated into one---{\tt irange 0 20 1} is inferred to have type {\tt Vec 20 int} in the existing compiler; with liveness and size information one could do something like linear register allocation in which arrays are assigned to memory slots.

This vindicates flat arrays; while banning arrays of functions \&c. may not be obvious to a functional programmer, studying this particular set of constraints has potential; one could use it to implement a compiler for a high-level language that produces performant and portable code.

\bibliographystyle{ACM-Reference-Format}
\bibliography{alloc.bib}

\end{document}
