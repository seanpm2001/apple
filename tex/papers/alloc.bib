@book{appel1998,
    author={Appel, Andrew},
    title={Modern Compiler Implementation in ML},
    year={1998},
    publisher={Cambridge University Press},
},
@a@rticle{hui2020,
author = {Hui, Roger K. W. and Kromberg, Morten J.},
title = {APL since 1978},
year = {2020},
issue_date = {June 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {4},
number = {HOPL},
url = {https://doi.org/10.1145/3386319},
doi = {10.1145/3386319},
abstract = {The Evolution of APL, the HOPL I paper by Falkoff and Iverson on APL, recounted the fundamental design principles which shaped the implementation of the APL language in 1966, and the early uses and other influences which shaped its first decade of enhancements.In the 40 years that have elapsed since HOPL I, several dozen APL implementations have come and gone. In the first decade or two, interpreters were typically born and buried along with the hardware or operating system that they were created for. More recently, the use of C as an implementation language provided APL interpreters with greater longevity and portability.APL started its life on IBM mainframes which were time-shared by multiple users. As the demand for computing resources grew and costs dropped, APL first moved in-house to mainframes, then to mini- and micro-computers. Today, APL runs on PCs and tablets, Apples and Raspberry Pis, smartphones and watches.The operating systems, and the software application platforms that APL runs on, have evolved beyond recognition. Tools like database systems have taken over many of the tasks that were initially implemented in APL or provided by the APL system, and new capabilities like parallel hardware have also changed the focus of design and implementation efforts through the years.The first wave of significant language enhancements occurred shortly after HOPL I, resulting in so-called second-generation APL systems. The most important feature of the second generation is the addition of general arrays—in which any item of an array can be another array—and a number of new functions and operators aligned with, if not always motivated by, the new data structures.The majority of implementations followed IBM’s path with APL2 “floating” arrays; others aligned themselves with SHARP APL and “grounded” arrays. While the APL2 style of APL interpreters came to dominate the mainstream of the APL community, two new cousins of APL descended from the SHARP APL family tree: J (created by Iverson and Hui) and k (created by Arthur Whitney).We attempt to follow a reasonable number of threads through the last 40 years, to identify the most important factors that have shaped the evolution of APL. We will discuss the details of what we believe are the most significant language features that made it through the occasionally unnatural selection imposed by the loss of habitats that disappeared with hardware, software platforms, and business models.The history of APL now spans six decades. It is still the case, as Falkoff and Iverson remarked at the end of the HOPL I paper, that:Although this is not the place to discuss the future, it should be remarked that the evolution of APL is far from finished.},
journal = {Proc. ACM Program. Lang.},
month = {jun},
articleno = {69},
numpages = {108},
keywords = {programming languages, higher-order functions, functional programming, executable mathematical notation, array programming, APL}
}
@inproceedings{kell2017,
author = {Kell, Stephen},
title = {Some were meant for C: the endurance of an unmanageable language},
year = {2017},
isbn = {9781450355308},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3133850.3133867},
doi = {10.1145/3133850.3133867},
abstract = {The C language leads a double life: as an application programming language of yesteryear, perpetuated by circumstance; and as a systems programming language which remains a weapon of choice decades after its creation. This essay is a C programmer's reaction to the call to abandon ship. It questions several aspects commonly held to define the experience of using C; these include unsafety, undefined behaviour, and the motivation of performance. It argues all these are in fact inessential; rather, it traces C's ultimate strength to a communicative design which cannot be understood within the usual conception of "a programming language", but can be seen as the antithesis of so-called "managed" languages. This communicativity is understood as facilitating the essential aspect of system-building: creating parts which interact with other remote parts---being "alongside" not "within", and of "alien" origin.},
booktitle = {Proceedings of the 2017 ACM SIGPLAN International Symposium on New Ideas, New Paradigms, and Reflections on Programming and Software},
pages = {229–245},
numpages = {17},
keywords = {virtual machine, undefined behavior, systems programming, safety, managed languages},
location = {Vancouver, BC, Canada},
series = {Onward! 2017}
}
@inproceedings{chakravarty2011,
    author      = {Chakravarty, Manuel M T and Keller, Gabriele and Lee, Sean and McDonell, Trevor L. and Grover, Vinod},
    title       = {{Accelerating Haskell array codes with multicore GPUs}},
    booktitle   = {DAMP '11: The 6th workshop on Declarative Aspects of Multicore Programming},
    publisher   = {ACM},
    year        = {2011},
    month       = jan
}
@inproceedings {munksgaard2022,
author = {P. Munksgaard and T. Henriksen and P. Sadayappan and C. Oancea},
booktitle = {2022 SC22: International Conference for High Performance Computing, Networking, Storage and Analysis (SC) (SC)},
title = {Memory Optimizations in an Array Language},
year = {2022},
volume = {},
issn = {2167-4337},
pages = {424-438},
abstract = {We present a technique for introducing and optimizing the use of memory in a functional array language, aimed at GPU execution, that supports correct-by-construction parallelism. Using linear memory access descriptors as building blocks, we define a notion of memory in the compiler IR that enables cost-free change-of-layout transformations (e.g., slicing, transposition), whose results can even be carried across control flow such as ifs/loops without manifestation in memory. The memory notion allows a graceful transition to an unsafe IR that is automatically optimized (1) to mix reads and writes to the same array inside a parallel construct, and (2) to map semantically different arrays to the same memory block. The result is code similar to what imperative users would write. Our evaluation shows that our optimizations have significant impact (1:1â€“2) and result in performance competitive to hand-written code from challenging benchmarks, such as Rodiniaâ€™s NW, LUD, Hotspot.},
keywords = {gpu;parallelism;functional programming;optimizing compiler},
doi = {},
url = {https://doi.ieeecomputersociety.org/},
publisher = {IEEE Computer Society},
address = {Los Alamitos, CA, USA},
month = {nov}
}
@inproceedings{hsu2023,
author = {Hsu, Aaron W. and Serr\~{a}o, Rodrigo Gir\~{a}o},
title = {U-Net CNN in APL: Exploring Zero-Framework, Zero-Library Machine Learning},
year = {2023},
isbn = {9798400701696},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589246.3595371},
doi = {10.1145/3589246.3595371},
abstract = {The APL notation would appear to be a clear match for convolutional neural networks, but traditional implementations of APL have lagged behind the performance of highly tuned, specialized frameworks designed to execute CNNs on the GPU. Moreover, most demonstrations of APL for neural networking have involved relatively small examples. We explore a more complex example in the U-net architecture and utilize a modern APL compiler with GPU support, Co-dfns, to compare the state of the art of APL against the current crop of specialized neural network frameworks in the form of PyTorch. We compare performance as well as the language design of APL for neural network programming and the clarity and transparency of the resulting code.

We found that the complete “from scratch” APL source was on par with the complexity of the PyTorch reference implementation, albeit more foreign, while being more concise and complete. We also found that when compiled with Co-dfns, despite the na\"{\i}ve implementation both of Co-dfns and our own code, performance on the GPU and the CPU were within a factor of 2.2 - 2.4 times that of the PyTorch implementation. We believe this suggests significant avenues of future exploration for machine learning language design, pedagogy, and implementation, both inside and outside of the APL community.},
booktitle = {Proceedings of the 9th ACM SIGPLAN International Workshop on Libraries, Languages and Compilers for Array Programming},
pages = {22–35},
numpages = {14},
keywords = {Neural Networks, Machine Learning, GPU, Compilers, Co-dfns, APL},
location = {Orlando, FL, USA},
series = {ARRAY 2023}
}

@article{harris2020,
	abstract = {Array programming provides a powerful, compact and expressive syntax for accessing, manipulating and operating on data in vectors, matrices and higher-dimensional arrays. NumPy is the primary array programming library for the Python language. It has an essential role in research analysis pipelines in fields as diverse as physics, chemistry, astronomy, geoscience, biology, psychology, materials science, engineering, finance and economics. For example, in astronomy, NumPy was an important part of the software stack used in the discovery of gravitational waves1 and in the first imaging of a black hole2. Here we review how a few fundamental array concepts lead to a simple and powerful programming paradigm for organizing, exploring and analysing scientific data. NumPy is the foundation upon which the scientific Python ecosystem is constructed. It is so pervasive that several projects, targeting audiences with specialized needs, have developed their own NumPy-like interfaces and array objects. Owing to its central position in the ecosystem, NumPy increasingly acts as an interoperability layer between such array computation libraries and, together with its application programming interface (API), provides a flexible framework to support the next decade of scientific and industrial analysis.},
	author = {Harris, Charles R. and Millman, K. Jarrod and van der Walt, St{\'e}fan J. and Gommers, Ralf and Virtanen, Pauli and Cournapeau, David and Wieser, Eric and Taylor, Julian and Berg, Sebastian and Smith, Nathaniel J. and Kern, Robert and Picus, Matti and Hoyer, Stephan and van Kerkwijk, Marten H. and Brett, Matthew and Haldane, Allan and del R{\'\i}o, Jaime Fern{\'a}ndez and Wiebe, Mark and Peterson, Pearu and G{\'e}rard-Marchant, Pierre and Sheppard, Kevin and Reddy, Tyler and Weckesser, Warren and Abbasi, Hameer and Gohlke, Christoph and Oliphant, Travis E.},
	date = {2020/09/01},
	date-added = {2024-03-31 11:37:37 -0400},
	date-modified = {2024-03-31 11:37:37 -0400},
	doi = {10.1038/s41586-020-2649-2},
	id = {Harris2020},
	isbn = {1476-4687},
	journal = {Nature},
	number = {7825},
	pages = {357--362},
	title = {Array programming with NumPy},
	url = {https://doi.org/10.1038/s41586-020-2649-2},
	volume = {585},
	year = {2020},
	bdsk-url-1 = {https://doi.org/10.1038/s41586-020-2649-2}}
@article{poletto1999,
author = {Poletto, Massimiliano and Sarkar, Vivek},
title = {Linear scan register allocation},
year = {1999},
issue_date = {Sept. 1999},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {21},
number = {5},
issn = {0164-0925},
url = {https://doi.org/10.1145/330249.330250},
doi = {10.1145/330249.330250},
abstract = {We describe a new algorithm for fast global register allocation called linear scan. This algorithm is not based on graph coloring, but allocates registers to variables in a single linear-time scan of the variables' live ranges. The linear scan algorithm is considerably faster than algorithms based on graph coloring, is simple to implement, and results in code that is almost as efficient as that obtained using more complex and time-consuming register allocators based on graph coloring. The algorithm is of interest in applications where compile time is a concern, such as dynamic compilation systems, “just-in-time” compilers, and interactive development environments.},
journal = {ACM Trans. Program. Lang. Syst.},
month = {sep},
pages = {895–913},
numpages = {19},
keywords = {register allocation, compilers, code optimization}
}
@inproceedings{10.1145/3460944.3464310,
author = {Henriksen, Troels and Elsman, Martin},
title = {Towards Size-Dependent Types for Array Programming},
year = {2021},
isbn = {9781450384667},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3460944.3464310},
doi = {10.1145/3460944.3464310},
abstract = {We present a type system for expressing size constraints on array types in an ML-style type system. The goal is to detect shape mismatches at compile-time, while being simpler than full dependent types. The main restrictions is that the only terms that can occur in types are array sizes, and syntactically they must be variables or constants. For those programs where this is not sufficient, we support a form of existential types, with the type system automatically managing the requisite book-keeping. We formalise a large subset of the type system in a small core language, which we prove sound. We also present an integration of the type system in the high-performance parallel functional language Futhark, and show on a collection of 44 representative programs that the restrictions in the type system are not too problematic in practice.},
booktitle = {Proceedings of the 7th ACM SIGPLAN International Workshop on Libraries, Languages and Compilers for Array Programming},
pages = {1â€“14},
numpages = {14},
keywords = {type systems, parallel programming, functional programming},
location = {Virtual, Canada},
series = {ARRAY 2021}
}
